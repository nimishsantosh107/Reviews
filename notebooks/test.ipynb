{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enchant dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['produced', 'producer']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords\n",
    "from nltk.corpus import stopwords \n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "text = \"i am produced by a producer\"\n",
    "text = [i for i in text.lower().split() if i not in stop]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shoot', 'dissipate', 'dupe', 'frivol_away', 'chump', 'mark', 'gull', 'tomfool', 'cod', 'slang', 'put_on', 'arse_around', 'patsy', 'fool', 'soft_touch', 'horse_around', 'sucker', 'fool_around', 'put_one_over', 'muggins', 'sap', 'mug', 'take_in', 'motley_fool', 'jester', 'befool', 'fool_away', 'fritter', 'saphead', 'fritter_away', 'put_one_across', 'fall_guy'}\n"
     ]
    }
   ],
   "source": [
    "#synonyms\n",
    "#from nltk.corpus import wordnet\n",
    "\n",
    "synonyms = []\n",
    "for syn in wordnet.synsets(\"fool\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "print(set(synonyms))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['the dumb Jack']\n",
      "Verbs: []\n",
      "Adj: ['dumb']\n"
     ]
    }
   ],
   "source": [
    "#POS tagging N/V\n",
    "#import spacy\n",
    "#nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "text = (\"the dumb Jack\")\n",
    "doc = nlp(text)\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "print(\"Adj:\", [token.lemma_ for token in doc if token.pos_ == \"ADJ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Active / Passive\n",
    "from modules.functions import is_active\n",
    "\n",
    "print(is_active(\"He is cutting wood with the saw\"))\n",
    "print(is_active(\"the wood is being cut by him with a saw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the 3 programs are being run by Jake's amazing computer wonderfully\""
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARE AND REPLACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules.functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-6eebd612349c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnum2words\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnum2words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_active\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modules.functions'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "from nltk.corpus import wordnet\n",
    "from num2words import num2words\n",
    "from modules.functions import is_active\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets sentence returns obj with POS tagged\n",
    "def tagSentence(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    obj = {}\n",
    "    obj[\"NOUN\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"NOUN\"]\n",
    "    obj[\"PROPN\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"PROPN\"]\n",
    "    obj[\"PRON\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"PRON\"]\n",
    "    obj[\"VERB\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"VERB\" and token.lemma_.lower() != \"be\"]\n",
    "    obj[\"ADJ\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"ADJ\"]\n",
    "    obj[\"ADV\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"ADV\"]\n",
    "    obj[\"NUM\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"NUM\"]\n",
    "    obj[\"SYM\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"SYM\"]\n",
    "    obj[\"X\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"X\"]\n",
    "    return obj\n",
    "\n",
    "#Only for sent2\n",
    "def reTagSentence(sentence2):\n",
    "    obj = {}\n",
    "    doc = nlp(sentence2)\n",
    "    obj[\"NOUN\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"NOUN\"]\n",
    "    obj[\"PROPN\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"PROPN\"]\n",
    "    obj[\"PRON\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"PRON\"]\n",
    "    obj[\"ADJ\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"ADJ\"]\n",
    "    obj[\"VERB\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"VERB\" and token.lemma_.lower() != \"be\"]\n",
    "    return obj\n",
    "\n",
    "#Gets obj with POS tagged, returns obj with POS tagged + synonyms(only for obj2)\n",
    "def findSynonyms(obj):\n",
    "    #NOUN SYNONYMS FOUND IN COMPARE() ITSELF DUE TO NOUN ORDER CHECK\n",
    "    #ADJ SYNONYMS FOUND IN COMPARE() ITSELF DUE TO ADJ ORDER CHECK\n",
    "    #VERB\n",
    "    if(len(obj[\"VERB\"])>0):\n",
    "        tempArr = []\n",
    "        for word in obj[\"VERB\"]:\n",
    "            for syn in wordnet.synsets(word):\n",
    "                for l in syn.lemmas():\n",
    "                    tempArr.append(l.name())\n",
    "        obj[\"VERB\"] = list(set(obj[\"VERB\"]+tempArr))\n",
    "    \n",
    "    #ADV   \n",
    "    if(len(obj[\"ADV\"])>0):\n",
    "        tempArr = []\n",
    "        for word in obj[\"ADV\"]:\n",
    "            for syn in wordnet.synsets(word):\n",
    "                for l in syn.lemmas():\n",
    "                    tempArr.append(l.name())\n",
    "        obj[\"ADV\"] = list(set(obj[\"ADV\"]+tempArr))\n",
    "    #X  \n",
    "    if(len(obj[\"X\"])>0):\n",
    "        tempArr = []\n",
    "        for word in obj[\"X\"]:\n",
    "            for syn in wordnet.synsets(word):\n",
    "                for l in syn.lemmas():\n",
    "                    tempArr.append(l.name())\n",
    "        obj[\"X\"] = list(set(obj[\"X\"]+tempArr))\n",
    "    return obj\n",
    "     \n",
    "#Comparison\n",
    "def compare(obj1,obj2,sentence2):\n",
    "    #original object 2\n",
    "    obj2a = reTagSentence(sentence2)\n",
    "    result = {}\n",
    "    #NOUN, PROPN, PRON, VERB, ADJ, ADV, NUM, SYM, X - CRITICAL\n",
    "    #NOUN\n",
    "    if(len(obj1[\"NOUN\"])>0):\n",
    "        result[\"NOUN\"] = 0\n",
    "        status = 0\n",
    "        for i in range(len(obj1[\"NOUN\"])): \n",
    "            word1 = obj1[\"NOUN\"][i]\n",
    "            for j in range(len(obj2[\"NOUN\"])): \n",
    "                word2 = obj2[\"NOUN\"][j]\n",
    "                tempArr = []\n",
    "                for syn in wordnet.synsets(word2):\n",
    "                    for l in syn.lemmas():\n",
    "                        tempArr.append(l.name())\n",
    "                for tempWord in tempArr:\n",
    "                    if(word1 == tempWord):\n",
    "                        status = 1\n",
    "                        sentence2 = sentence2.replace(word2,word1)\n",
    "                        result[\"NOUN\"] += 1\n",
    "                        break\n",
    "            if(status == 1):\n",
    "                status = 0\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    #PROPN      \n",
    "    if(len(obj1[\"PROPN\"])>0):\n",
    "        result[\"PROPN\"] = 0\n",
    "        for i in range(len(obj1[\"PROPN\"])): \n",
    "            word1 = obj1[\"PROPN\"][i]\n",
    "            for word2 in obj2[\"PROPN\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"PROPN\"] += 1\n",
    "    #PRON               \n",
    "    if(len(obj1[\"PRON\"])>0):\n",
    "        result[\"PRON\"] = 0\n",
    "        for word1 in obj1[\"PRON\"]:\n",
    "            for word2 in obj2[\"PRON\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"PRON\"] += 1\n",
    "    #VERB\n",
    "    if(len(obj1[\"VERB\"])>0):\n",
    "        result[\"VERB\"] = 0\n",
    "        for word1 in obj1[\"VERB\"]:\n",
    "            for word2 in obj2[\"VERB\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"VERB\"] += 1 \n",
    "    #ADJ \n",
    "    if(len(obj1[\"ADJ\"])>0):\n",
    "        result[\"ADJ\"] = 0\n",
    "        status = 0\n",
    "        for i in range(len(obj1[\"ADJ\"])): \n",
    "            word1 = obj1[\"ADJ\"][i]\n",
    "            for j in range(len(obj2[\"ADJ\"])): \n",
    "                word2 = obj2[\"ADJ\"][j]\n",
    "                tempArr = []\n",
    "                for syn in wordnet.synsets(word2):\n",
    "                    for l in syn.lemmas():\n",
    "                        tempArr.append(l.name())\n",
    "                for tempWord in tempArr:\n",
    "                    if(word1 == tempWord):\n",
    "                        status = 1\n",
    "                        sentence2 = sentence2.replace(word2,word1)\n",
    "                        result[\"ADJ\"] += 1\n",
    "                        break\n",
    "\n",
    "    #ADV\n",
    "    if(len(obj1[\"ADV\"])>0):\n",
    "        result[\"ADV\"] = 0\n",
    "        for word1 in obj1[\"ADV\"]:\n",
    "            for word2 in obj2[\"ADV\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"ADV\"] += 1 \n",
    "    #NUM     \n",
    "    if(len(obj1[\"NUM\"])>0):\n",
    "        #NUM2WORD\n",
    "        for i in range(len(obj1[\"NUM\"])):\n",
    "            if(obj1[\"NUM\"][i].isdigit()):\n",
    "                obj1[\"NUM\"][i] = num2words(obj1[\"NUM\"][i])\n",
    "        for i in range(len(obj2[\"NUM\"])):\n",
    "            if(obj2[\"NUM\"][i].isdigit()):\n",
    "                obj2[\"NUM\"][i] = num2words(obj2[\"NUM\"][i])\n",
    "        #NORMAL\n",
    "        result[\"NUM\"] = 0\n",
    "        for word1 in obj1[\"NUM\"]:\n",
    "            for word2 in obj2[\"NUM\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"NUM\"] += 1\n",
    "    #SYM\n",
    "    if(len(obj1[\"SYM\"])>0):\n",
    "        result[\"SYM\"] = 0\n",
    "        for word1 in obj1[\"SYM\"]:\n",
    "            for word2 in obj2[\"SYM\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"SYM\"] += 1\n",
    "    #X-OTHERS\n",
    "    if(len(obj1[\"X\"])>0):\n",
    "        result[\"X\"] = 0\n",
    "        for word1 in obj1[\"X\"]:\n",
    "            for word2 in obj2[\"X\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"X\"] += 1\n",
    "    tempObj = {\n",
    "        'NOUN':len(obj1['NOUN']),\n",
    "        'PROPN':len(obj1['PROPN']),\n",
    "        'PRON':len(obj1['PRON']),\n",
    "        'VERB':len(obj1['VERB']),\n",
    "        'ADJ':len(obj1['ADJ']),\n",
    "        'ADV':len(obj1['ADV']),\n",
    "        'SYM':len(obj1['SYM']),\n",
    "        'NUM':len(obj1['NUM']),\n",
    "        'X':len(obj1['X'])\n",
    "    }\n",
    "    res = {\n",
    "        'teachArr':tempObj,\n",
    "        'studArr':result\n",
    "    }\n",
    "    #TUPLE UNPACK AND GET BOTH VALUES\n",
    "    return res,sentence2\n",
    "\n",
    "#Is active\n",
    "def is_active(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    passive_rule = [{'DEP': 'nsubjpass'}, {'DEP': 'aux', 'OP': '*'}, {'DEP': 'auxpass'}, {'TAG': 'VBN'}]\n",
    "    matcher.add('Passive', None, passive_rule)\n",
    "    matches = matcher(doc)\n",
    "    if matches:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NOUN': ['calculator', 'program'], 'PROPN': ['jake'], 'PRON': [], 'VERB': ['execute'], 'ADJ': ['stupid', 'awesome'], 'ADV': ['marvellously'], 'NUM': ['three'], 'SYM': [], 'X': []}\n",
      "{'NOUN': ['program', 'computer'], 'PROPN': ['jake'], 'PRON': [], 'VERB': ['run'], 'ADJ': ['amazing'], 'ADV': ['wonderfully'], 'NUM': ['3'], 'SYM': [], 'X': []}\n"
     ]
    }
   ],
   "source": [
    "sent1 = \"stupid Jake's awesome calculator is executing the three programs marvellously\"\n",
    "sent2 = \"the 3 programs are being run by Jake's amazing computer wonderfully\"\n",
    "object1 = tagSentence(sent1)\n",
    "object2 = tagSentence(sent2)\n",
    "print(object1)\n",
    "print(object2)\n",
    "#OBJECT1 #TEACHER OBJECT NOT TO BE SYNONYMIZED - TO CHECK IF EVERYTHING IS PRESENT\n",
    "object2 = findSynonyms(object2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stupid Jake's awesome calculator is executing the three programs marvellously\n",
      "the 3 programs are being run by Jake's amazing computer wonderfully\n",
      "{'teachArr': {'NOUN': 2, 'PROPN': 1, 'PRON': 0, 'VERB': 1, 'ADJ': 2, 'ADV': 1, 'SYM': 0, 'NUM': 1, 'X': 0}, 'studArr': {'NOUN': 2, 'PROPN': 1, 'VERB': 1, 'ADJ': 1, 'ADV': 1, 'NUM': 1}}\n",
      "stupid Jake's awesome calculator is executing the three programs marvellously\n",
      "the 3 programs are being run by Jake's awesome calculator wonderfully\n"
     ]
    }
   ],
   "source": [
    "print(sent1)\n",
    "print(sent2)\n",
    "res,sent2 = compare(object1,object2,sent2)\n",
    "print(res)\n",
    "print(sent1)\n",
    "print(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end of compare and replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOUN/ADJECTIVE ORDER CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These sentences will be with replaced words for sent2 alone\n",
    "#For NOUN check\n",
    "def NCsplitOnVerb(sentence):\n",
    "    sent = {}\n",
    "    doc = nlp(sentence)\n",
    "    sent[\"TYPE\"] = is_active(sentence)\n",
    "    sent[\"NPV\"] = [token.lemma_.lower() for token in doc if token.pos_==\"NOUN\" \n",
    "     or token.pos_==\"PRON\" \n",
    "     or token.pos_==\"PROPN\"\n",
    "     or token.pos_==\"VERB\" and token.lemma_.lower()!=\"be\"]\n",
    "    sent[\"NPV\"] = ' '.join(sent[\"NPV\"])\n",
    "    sent[\"V\"] = [token.lemma_.lower() for token in doc if token.pos_==\"VERB\" and token.lemma_.lower()!=\"be\"]\n",
    "    sent[\"NP\"]= sent[\"NPV\"].split(sent[\"V\"][0])\n",
    "    sent[\"NP\"] = [word.replace(' ','') for word in sent[\"NP\"]]\n",
    "    sent[\"NP\"] = [''.join(sorted(word)) for word in sent[\"NP\"]]\n",
    "    return sent\n",
    "\n",
    "#Check order of appearance of a noun\n",
    "def checkOrderOfNoun(sent1,sent2):\n",
    "    sent1obj = NCsplitOnVerb(sent1)\n",
    "    sent2obj = NCsplitOnVerb(sent2)\n",
    "    index1 = []\n",
    "    index2 = []\n",
    "    for i in range(len(sent1obj[\"NP\"])):\n",
    "        index1.append(i)\n",
    "        try:\n",
    "            index2.append(sent2obj[\"NP\"].index(sent1obj[\"NP\"][i]))\n",
    "        except:\n",
    "            return False\n",
    "    if(sent1obj[\"TYPE\"]==sent2obj[\"TYPE\"]):\n",
    "        #len(index1) = len(index2)\n",
    "        for i in range(len(index1)):\n",
    "            if(index1[i]!=index2[i]):\n",
    "                return False\n",
    "        return True\n",
    "    elif(sent1obj[\"TYPE\"]!=sent2obj[\"TYPE\"]):\n",
    "        for i in range(len(index1)):\n",
    "            if(index1[i]==index2[i]):\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For ADJ check\n",
    "def ACsplitOnVerb(sentence):\n",
    "    sent = {}\n",
    "    doc = nlp(sentence)\n",
    "    sent[\"TYPE\"] = is_active(sentence)\n",
    "    sent[\"NPVA\"] = [token.lemma_.lower() for token in doc if token.pos_==\"NOUN\" \n",
    "     or token.pos_==\"PRON\" \n",
    "     or token.pos_==\"PROPN\"\n",
    "     or token.pos_==\"ADJ\"\n",
    "     or token.pos_==\"VERB\" and token.lemma_.lower()!=\"be\"]\n",
    "    sent[\"NPVA\"] = ' '.join(sent[\"NPVA\"])\n",
    "    sent[\"V\"] = [token.lemma_.lower() for token in doc if token.pos_==\"VERB\" and token.lemma_.lower()!=\"be\"]\n",
    "    sent[\"NPA\"]= sent[\"NPVA\"].split(sent[\"V\"][0])\n",
    "    sent[\"NPA\"] = [word.replace(' ','') for word in sent[\"NPA\"]]\n",
    "    sent[\"NPA\"] = [''.join(sorted(word)) for word in sent[\"NPA\"]]\n",
    "    return sent\n",
    "\n",
    "#Check order of appearance of an adjective\n",
    "def checkOrderOfAdjective(sent1,sent2):\n",
    "    sent1obj = ACsplitOnVerb(sent1)\n",
    "    sent2obj = ACsplitOnVerb(sent2)\n",
    "    index1 = []\n",
    "    index2 = []\n",
    "    for i in range(len(sent1obj[\"NPA\"])):\n",
    "        index1.append(i)\n",
    "        try:\n",
    "            index2.append(sent2obj[\"NPA\"].index(sent1obj[\"NPA\"][i]))\n",
    "        except:\n",
    "            return False\n",
    "    if(sent1obj[\"TYPE\"]==sent2obj[\"TYPE\"]):\n",
    "        #len(index1) = len(index2)\n",
    "        for i in range(len(index1)):\n",
    "            if(index1[i]!=index2[i]):\n",
    "                return False\n",
    "        return True\n",
    "    elif(sent1obj[\"TYPE\"]!=sent2obj[\"TYPE\"]):\n",
    "        for i in range(len(index1)):\n",
    "            if(index1[i]==index2[i]):\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkOrderOfNoun(sent1,sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkOrderOfNoun(\"Jack shot Bill\",\"Bill was shot by Jack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkOrderOfAdjective(sent1,sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkOrderOfAdjective(\"hot Jack shot Bill\",\"Bill was shot by hot Jack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###END###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMILARITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = {\n",
    "    'teachMark' :{'NOUN': 2, 'PROPN': 1, 'PRON':0, 'VERB': 1, 'ADJ': 2, 'ADV': 1, 'SYM':0 ,'NUM': 1},\n",
    "    'studMark' :{'NOUN': 2, 'PROPN': 1, 'VERB': 1, 'ADJ': 0, 'ADV': 0, 'NUM': 1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simCheck(obj, studSum=0 ,teachSum=0): \n",
    "    FACT = {'NOUN': 1, 'PROPN': 1, 'PRON':1, 'VERB': 1, 'ADJ': 0.3, 'ADV': 0.3, 'SYM':1 ,'NUM': 1}\n",
    "    teachMark = obj['teachMark']\n",
    "    studMark = obj['studMark']\n",
    "    for key in teachMark:\n",
    "        if(teachMark[key]!=0):\n",
    "            try:\n",
    "                studMark[key]\n",
    "                totalval = teachMark[key]\n",
    "                val = ((teachMark[key]-studMark[key])*FACT[key])+studMark[key]\n",
    "                studSum+=val\n",
    "                teachSum+=totalval\n",
    "            except:\n",
    "                continue\n",
    "    return studSum/teachSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7374999999999999"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simCheck(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHUNK -> COMPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.compare import compare, is_active, checkOrderOfNoun, checkOrderOfAdjective\n",
    "from modules.metrics import simCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert teach array to this format\n",
    "teach = [\n",
    "        \"The dog is chasing the fat cat\",\n",
    "        \"The cat is eating the mouse\",\n",
    "        \"The mouse is eating food\"\n",
    "]\n",
    "\n",
    "student = [\n",
    "    \"The mouse is laughing\",\n",
    "    \"The cat is being chased by the dog\",\n",
    "    \"the mouse is being eaten by the cat\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teach and student are array of sentences\n",
    "#AFTER CHUNKING\n",
    "\n",
    "######## ADJUST SIM SCORE MULTIPLICATION\n",
    "def compareMain(teach,student):\n",
    "    arr=[]\n",
    "    for i in range(len(teach)):\n",
    "        obj={}\n",
    "        obj['s']=teach[i]\n",
    "        obj['c']=0\n",
    "        arr.append(obj)\n",
    "    teach = arr\n",
    "    for teachObj in teach:\n",
    "        for sent in student:\n",
    "            res , sent2 = compare(teachObj['s'],sent)\n",
    "            simScore = simCheck(res)\n",
    "            if(res['teachMark']['VERB']>0):\n",
    "                if(checkOrderOfNoun(teachObj['s'],sent2)==False):\n",
    "                    simScore*=0\n",
    "                if(checkOrderOfAdjective(teachObj['s'],sent2)==False):\n",
    "                    simScore*=0.95              #################\n",
    "            if(simScore>0.4):                   #################\n",
    "                teachObj['SIM'] = simScore\n",
    "                teachObj['c']=1\n",
    "    #teach is an object with attribute 's' , 'c' and 'SIM' if matched(result)\n",
    "    return teach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compareMain(teach,student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c08785e04264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
