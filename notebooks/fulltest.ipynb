{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"given 2 string compare how similar they are\"\"\"\n",
    "\n",
    "#ORDER OF IMPORTANCE:\n",
    "#     NOUN: noun\n",
    "#     PROPN: proper noun\n",
    "#     PRON: pronoun\n",
    "#     VERB: verb\n",
    "#     ADJ: adjective\n",
    "#     ADV: adverb\n",
    "#     NUM: numeral\n",
    "#     SYM: symbol\n",
    "#     X: other\n",
    "\n",
    "#LIST OF FUNCTIONS:\n",
    "#   tagSentence\n",
    "#   reTagSentence\n",
    "#   findSynonyms\n",
    "#   compare - \n",
    "#   is_active\n",
    "#   NCsplitOnVerb\n",
    "#   checkOrderOfNoun - \n",
    "#   ACsplitOnVerb\n",
    "#   checkOrderOfAdjective - \n",
    "\n",
    "\n",
    "##SPACY IMPORTS\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "##NLTK IMPORTS\n",
    "from nltk.corpus import wordnet\n",
    "from num2words import num2words\n",
    "##OTHER IMPORTS\n",
    "\n",
    "\n",
    "###chunker.py\n",
    "def resolve_co_reference(text):\n",
    "    import neuralcoref\n",
    "    nlpa = spacy.load(\"en_core_web_sm\")\n",
    "    '''\n",
    "    The coref model calculates the probabilities of links between The main occurence and a reference of that\n",
    "    main occurence and on the basis of that replaces every reference with the main occurence it is referring to\n",
    "    '''\n",
    "    coref = neuralcoref.NeuralCoref(nlpa.vocab) # initialize the neuralcoref with spacy's vocabulary\n",
    "    nlpa.add_pipe(coref, name='neuralcoref') #add the coref model to pipe\n",
    "    doc = nlpa(text)\n",
    "    if doc._.has_coref: ## if coreference is possible\n",
    "        return doc._.coref_resolved ##return the sentence with all references replaced\n",
    "    else:\n",
    "        return text ##else return text as it is \n",
    "\n",
    "def chunk(sent):\n",
    "#     sent=resolve_co_reference(sent)\n",
    "    conj = set(('and', 'or' ,'but','while','so','because','where','however','whereas'))\n",
    "    beverbs=set(('is','was','are','were'))\n",
    "    wdt=set(('which','that'))\n",
    "    l=[1,2,3]\n",
    "    tagged_list=[[]]\n",
    "    i=0\n",
    "    doc=nlp(sent)\n",
    "    for token in doc:\n",
    "        # if (token.lemma_==\"be\"):\n",
    "        #   l[0]=\"be\"\n",
    "        # else:\n",
    "        #   l[0]=token.text\n",
    "        l[0]=token.text\n",
    "        l[1]=token.tag_\n",
    "        if(token.dep_=='nsubj' and token.tag_.startswith(\"W\")==False):\n",
    "            l[2]=1\n",
    "        else:\n",
    "            l[2]=0\n",
    "        tagged_list.insert(i,l)\n",
    "        l=[1,2,3]\n",
    "        i=i+1\n",
    "\n",
    "    noun=-1\n",
    "    i=0\n",
    "    while(i<len(tagged_list)-1):\n",
    "        if(tagged_list[i][1].find(\"NN\")!=-1):\n",
    "            noun=i\n",
    "        if(tagged_list[i][0]in beverbs):\n",
    "            if(i<len(tagged_list)-2 and tagged_list[i+1][1].startswith(\"V\") and not tagged_list[i+1][1].startswith(\"VBG\")):\n",
    "                tagged_list[noun][2]=3\n",
    "        i=i+1\n",
    "    #print(tagged_list)\n",
    "\n",
    "    n=[[]]\n",
    "    ind=0\n",
    "    ind2=-1\n",
    "    i=0\n",
    "    subj=\"\"\n",
    "    lis=[]\n",
    "    flag=-1\n",
    "    find=-1\n",
    "    subj_type=-1\n",
    "    while(i<len(tagged_list)-1):\n",
    "        if(tagged_list[i][0] in wdt and i+1<len(tagged_list)-1 and tagged_list[i+1][1].find(\"VB\")!=-1):\n",
    "            if(i-2>=0 and tagged_list[i-1][0]==\",\"):\n",
    "                tagged_list[i][0]=tagged_list[i-2][0]\n",
    "                tagged_list[i][2]=1\n",
    "                tagged_list[i][1]=tagged_list[i-2][1]\n",
    "            else:\n",
    "                tagged_list[i-1][2]=1\n",
    "            subj=tagged_list[i-1][0]\n",
    "        i=i+1\n",
    "    i=0\n",
    "    while(i<len(tagged_list)-1):\n",
    "        if(tagged_list[i][2]==1 or tagged_list[i][2]==3):\n",
    "            subj=tagged_list[i][0]\n",
    "            subj_type=tagged_list[i][2]\n",
    "        if(tagged_list[i][1]==\"CC\"  or tagged_list[i][0] in conj or tagged_list[i][0]==\",\" or tagged_list[i][0]==\";\" or tagged_list[i][0]==\".\" or(tagged_list[i][0]in wdt and i+1<len(tagged_list)-1 and tagged_list[i+1][1].find(\"VB\")==-1)):\n",
    "            j=i+1\n",
    "            while(j<len(tagged_list)-1 and tagged_list[j][1].find(\"NN\")==-1 and tagged_list[j][1].find(\"VB\")==-1):\n",
    "                j=j+1\n",
    "            if(j<len(tagged_list)-1and tagged_list[j][1].find(\"NN\")!=-1):\n",
    "                \n",
    "                if((tagged_list[j][2]==1 or tagged_list[j][2]==3)):\n",
    "                    if(ind2!=-1 and ind2!=ind):\n",
    "                        find=find+1                 \n",
    "                        while(find<len(tagged_list)-1 and (tagged_list[find][1]!=\"CC\"  and tagged_list[find][0] not in conj and tagged_list[find][0]!=\",\" and tagged_list[find][0]!=\";\" and tagged_list[find][0]!=\".\" and(tagged_list[i][0]not in wdt or (i+1<len(tagged_list)-1 and tagged_list[i+1][1].find(\"VB\")!=-1)))):\n",
    "                            find=find+1\n",
    "                        n.append([tagged_list[x][0] for x in range(ind2,i) if(x not in range(ct,find+1))])\n",
    "                        ind2=-1\n",
    "                    else:\n",
    "                        for x in range(ind,i):\n",
    "                            if(tagged_list[x][1]==\"CC\"  or tagged_list[x][0] in conj or tagged_list[x][0]==\",\" or tagged_list[x][0]==\";\" or tagged_list[x][0]==\".\" or (tagged_list[x][0]in wdt and x+1<len(tagged_list)-1 and tagged_list[x+1][1].find(\"VB\")==-1) ):\n",
    "                                if(x>ind and x<i-1):\n",
    "                                    if((tagged_list[x-1][2]== 1 or tagged_list[x-1][2]==2)):\n",
    "                                        y=x+1\n",
    "                                        while(y<len(tagged_list)-1 and tagged_list[y][1].find(\"NN\")==-1 and tagged_list[y][1].find(\"VB\")==-1):\n",
    "                                            y=y+1\n",
    "                                        if(tagged_list[y][2]==1 or tagged_list[y][2]==2 or tagged_list[y][2]==3):\n",
    "                                            if(len(lis)==0):\n",
    "                                                lis.append(x-1)\n",
    "                                            lis.append(y)\n",
    "                        for l in range(len(lis)):\n",
    "                            n.append([tagged_list[x][0] for x in range(ind,i) if(x == lis[l] or x>lis[len(lis)-1]) or (l==0 and x<lis[0]) or (l>0 and x>lis[l-1]) and x<=lis[l]])\n",
    "                        if(len(lis)==0):\n",
    "                            n.append([tagged_list[x][0] for x in range(ind,i)])\n",
    "                    lis=[]\n",
    "                    ind =i+1\n",
    "                elif(i-1>=0 and (tagged_list[i-1][2]==1 or tagged_list[i-1][2]==2 or tagged_list[i-1][2]==3)):\n",
    "                    tagged_list[j][2]=2\n",
    "                    subj=subj+\" \"+tagged_list[i][0]+\" \"+tagged_list[j][0]\n",
    "\n",
    "                else:\n",
    "                    if(ind2==-1):\n",
    "                        ind2=ind\n",
    "                    ct=ind2\n",
    "                    while(ct<i-1 and ((tagged_list[ct][1].find(\"NN\")==-1 or tagged_list[ct][1].find(\"VB\")==-1) or (tagged_list[ct][2]==1 or tagged_list[ct][2]==2 or tagged_list[ct][2]==3 ))):\n",
    "                        ct=ct+1\n",
    "                    if(flag!=ind2):\n",
    "                        n.append([tagged_list[x][0] for x in range(ind2,i)])\n",
    "                        flag=ind2\n",
    "                        find=ct\n",
    "                    else:\n",
    "                        find=find+1                 \n",
    "                        while(find<len(tagged_list)-1 and (tagged_list[find][1]!=\"CC\"  and tagged_list[find][0] not in conj and tagged_list[find][0]!=\",\" and tagged_list[find][0]!=\";\" and tagged_list[find][0]!=\".\" and(tagged_list[i][0]not in wdt or (i+1<len(tagged_list)-1 and tagged_list[i+1][1].find(\"VB\")!=-1)))):\n",
    "                            find=find+1\n",
    "                        n.append([tagged_list[x][0] for x in range(ind2,i) if(x not in range(ct,find+1))])\n",
    "                    ind=i+1 #ADDED NOW\n",
    "\n",
    "\n",
    "\n",
    "            elif(j<len(tagged_list)-1 and tagged_list[j][1].find(\"VB\")!=-1):\n",
    "                if(ind2!=-1 and ind2!=ind):\n",
    "                    find=find+1                 \n",
    "                    while(find<len(tagged_list)-1 and (tagged_list[find][1]!=\"CC\"  and tagged_list[find][0] not in conj and tagged_list[find][0]!=\",\" and tagged_list[find][0]!=\";\" and tagged_list[find][0]!=\".\" and(tagged_list[i][0]not in wdt or (i+1<len(tagged_list)-1 and tagged_list[i+1][1].find(\"VB\")!=-1)))):\n",
    "                        find=find+1\n",
    "                    n.append([tagged_list[x][0] for x in range(ind2,i) if(x not in range(ct,find+1))])\n",
    "                    ind2=-1\n",
    "                else:\n",
    "                    for x in range(ind,i): #TO SEPARATE SUBJECTS\n",
    "                        if(tagged_list[x][1]==\"CC\"  or tagged_list[x][0] in conj or tagged_list[x][0]==\",\" or tagged_list[x][0]==\";\" or tagged_list[x][0]==\".\" or (tagged_list[x][0]in wdt and x+1<len(tagged_list)-1 and tagged_list[x+1][1].find(\"VB\")==-1) ):\n",
    "                            if(x>ind and x<i-1):\n",
    "                                if((tagged_list[x-1][2]== 1 or tagged_list[x-1][2]==2)):\n",
    "                                    y=x+1\n",
    "                                    while(y<len(tagged_list)-1 and tagged_list[y][1].find(\"NN\")==-1 and tagged_list[y][1].find(\"VB\")==-1):\n",
    "                                        y=y+1\n",
    "                                    if(tagged_list[y][2]==1 or tagged_list[y][2]==2 or tagged_list[y][2]==3):\n",
    "                                        if(len(lis)==0):\n",
    "                                            lis.append(x-1)\n",
    "                                        lis.append(y)\n",
    "                    for l in range(len(lis)):\n",
    "                        n.append([tagged_list[x][0] for x in range(ind,i) if(x == lis[l] or x>lis[len(lis)-1]) or (l==0 and x<lis[0]) or (l>0 and x>lis[l-1]) and x<=lis[l]])\n",
    "                    if(len(lis)==0):\n",
    "                        n.append([tagged_list[x][0] for x in range(ind,i)])\n",
    "                if(i+1<len(tagged_list)-1 and tagged_list[i+1][1]!=\"PRP\"):\n",
    "                    if(subj_type==3):\n",
    "                        tagged_list[i][0]=subj+\" was \"\n",
    "                    else:\n",
    "                        tagged_list[i][0]=subj\n",
    "                    ind=i\n",
    "                else:\n",
    "                    ind=i+1\n",
    "                lis=[]\n",
    "\n",
    "        \n",
    "        i=i+1\n",
    "    if(ind2!=-1 and ind2!=ind):\n",
    "        find=find+1                 \n",
    "        while(find<len(tagged_list)-1 and (tagged_list[find][1]!=\"CC\"  and tagged_list[find][0] not in conj and tagged_list[find][0]!=\",\" and tagged_list[find][0]!=\";\" and tagged_list[find][0]!=\".\" and(tagged_list[find][0]not in wdt or (find+1<len(tagged_list)-1 and tagged_list[find+1][1].find(\"VB\")!=-1)))):\n",
    "            find=find+1\n",
    "        n.append([tagged_list[x][0] for x in range(ind2,i) if(x not in range(ct,find+1))])\n",
    "        ind2=-1;\n",
    "    else:   \n",
    "        for x in range(ind,i):\n",
    "            if(tagged_list[x][1]==\"CC\"  or tagged_list[x][0] in conj or tagged_list[x][0]==\",\" or tagged_list[x][0]==\";\" or tagged_list[x][0]==\".\" or (tagged_list[x][0]in wdt and x+1<len(tagged_list)-1 and tagged_list[x+1][1].find(\"VB\")==-1) ):\n",
    "                if(x>ind and x<i-1):\n",
    "                    if((tagged_list[x-1][2]== 1 or tagged_list[x-1][2]==2)):\n",
    "                        y=x+1\n",
    "                        while(y<len(tagged_list)-1 and tagged_list[y][1].find(\"NN\")==-1 and tagged_list[y][1].find(\"VB\")==-1):\n",
    "                            y=y+1\n",
    "                        if(tagged_list[y][2]==1 or tagged_list[y][2]==2):\n",
    "                            if(len(lis)==0):\n",
    "                                lis.append(x-1)\n",
    "                            lis.append(y)\n",
    "        for l in range(len(lis)):\n",
    "            n.append([tagged_list[x][0] for x in range(ind,i) if(x == lis[l] or x>lis[len(lis)-1]) or (l==0 and x<lis[0]) or (l>0 and x>lis[l-1]) and x<=lis[l]])\n",
    "        if(len(lis)==0):\n",
    "            n.append([tagged_list[x][0] for x in range(ind,i)])\n",
    "    stringArr = []\n",
    "    for arr in n:\n",
    "        if(len(arr)>0):\n",
    "            stringArr.append(' '.join(arr))\n",
    "    return stringArr\n",
    "\n",
    "####### ADJUST FACTORS\n",
    "def simCheck(obj, studSum=0 ,teachSum=0): \n",
    "    FACT = {'NOUN': 1, 'PROPN': 1, 'PRON':1, 'VERB': 1, 'ADJ': 0.3, 'ADV': 0.3, 'SYM':1 ,'NUM': 1}\n",
    "    teachMark = obj['teachMark']\n",
    "    studMark = obj['studMark']\n",
    "    for key in teachMark:\n",
    "        if(teachMark[key]!=0):\n",
    "            try:\n",
    "                studMark[key]\n",
    "                totalval = teachMark[key]\n",
    "                val = ((teachMark[key]-studMark[key])*FACT[key])+studMark[key]\n",
    "                studSum+=val\n",
    "                teachSum+=totalval\n",
    "            except:\n",
    "                continue\n",
    "    return studSum/teachSum\n",
    "\n",
    "#Gets sentence returns obj with POS tagged\n",
    "def tagSentence(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    obj = {}\n",
    "    obj[\"NOUN\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"NOUN\"]\n",
    "    obj[\"PROPN\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"PROPN\"]\n",
    "    obj[\"PRON\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"PRON\"]\n",
    "    obj[\"VERB\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"VERB\" and token.lemma_.lower() != \"be\"]\n",
    "    obj[\"ADJ\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"ADJ\"]\n",
    "    obj[\"ADV\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"ADV\"]\n",
    "    obj[\"NUM\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"NUM\"]\n",
    "    obj[\"SYM\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"SYM\"]\n",
    "    obj[\"X\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"X\"]\n",
    "    return obj\n",
    "\n",
    "#Only for sent2\n",
    "def reTagSentence(sentence2):\n",
    "    obj = {}\n",
    "    doc = nlp(sentence2)\n",
    "    obj[\"NOUN\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"NOUN\"]\n",
    "    obj[\"PROPN\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"PROPN\"]\n",
    "    obj[\"PRON\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"PRON\"]\n",
    "    obj[\"ADJ\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"ADJ\"]\n",
    "    obj[\"VERB\"] = [token.lemma_.lower() for token in doc if token.pos_ == \"VERB\" and token.lemma_.lower() != \"be\"]\n",
    "    return obj\n",
    "\n",
    "#Gets obj with POS tagged, returns obj with POS tagged + synonyms(only for obj2)\n",
    "def findSynonyms(obj):\n",
    "    #NOUN SYNONYMS FOUND IN COMPARE() ITSELF DUE TO NOUN ORDER CHECK\n",
    "    #ADJ SYNONYMS FOUND IN COMPARE() ITSELF DUE TO ADJ ORDER CHECK\n",
    "    #VERB\n",
    "    if(len(obj[\"VERB\"])>0):\n",
    "        tempArr = []\n",
    "        for word in obj[\"VERB\"]:\n",
    "            for syn in wordnet.synsets(word):\n",
    "                for l in syn.lemmas():\n",
    "                    tempArr.append(l.name())\n",
    "        obj[\"VERB\"] = list(set(obj[\"VERB\"]+tempArr))\n",
    "    \n",
    "    #ADV   \n",
    "    if(len(obj[\"ADV\"])>0):\n",
    "        tempArr = []\n",
    "        for word in obj[\"ADV\"]:\n",
    "            for syn in wordnet.synsets(word):\n",
    "                for l in syn.lemmas():\n",
    "                    tempArr.append(l.name())\n",
    "        obj[\"ADV\"] = list(set(obj[\"ADV\"]+tempArr))\n",
    "    #X  \n",
    "    if(len(obj[\"X\"])>0):\n",
    "        tempArr = []\n",
    "        for word in obj[\"X\"]:\n",
    "            for syn in wordnet.synsets(word):\n",
    "                for l in syn.lemmas():\n",
    "                    tempArr.append(l.name())\n",
    "        obj[\"X\"] = list(set(obj[\"X\"]+tempArr))\n",
    "    return obj\n",
    "    \n",
    "#______________MAIN______________     \n",
    "#Comparison between two sentences\n",
    "def compare(sentence1,sentence2):\n",
    "    obj1 = tagSentence(sentence1)\n",
    "    obj2 = tagSentence(sentence2)\n",
    "    obj2 = findSynonyms(obj2)\n",
    "    #original object 2\n",
    "    obj2a = reTagSentence(sentence2)\n",
    "    result = {}\n",
    "    #NOUN, PROPN, PRON, VERB, ADJ, ADV, NUM, SYM, X - CRITICAL\n",
    "    #NOUN\n",
    "    if(len(obj1[\"NOUN\"])>0):\n",
    "        result[\"NOUN\"] = 0\n",
    "        status = 0\n",
    "        for i in range(len(obj1[\"NOUN\"])): \n",
    "            word1 = obj1[\"NOUN\"][i]\n",
    "            for j in range(len(obj2[\"NOUN\"])): \n",
    "                word2 = obj2[\"NOUN\"][j]\n",
    "                tempArr = []\n",
    "                for syn in wordnet.synsets(word2):\n",
    "                    for l in syn.lemmas():\n",
    "                        tempArr.append(l.name())\n",
    "                for tempWord in tempArr:\n",
    "                    if(word1 == tempWord):\n",
    "                        status = 1\n",
    "                        sentence2 = sentence2.replace(word2,word1)\n",
    "                        result[\"NOUN\"] += 1\n",
    "                        break\n",
    "            if(status == 1):\n",
    "                status = 0\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    #PROPN      \n",
    "    if(len(obj1[\"PROPN\"])>0):\n",
    "        result[\"PROPN\"] = 0\n",
    "        for i in range(len(obj1[\"PROPN\"])): \n",
    "            word1 = obj1[\"PROPN\"][i]\n",
    "            for word2 in obj2[\"PROPN\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"PROPN\"] += 1\n",
    "    #PRON               \n",
    "    if(len(obj1[\"PRON\"])>0):\n",
    "        result[\"PRON\"] = 0\n",
    "        for word1 in obj1[\"PRON\"]:\n",
    "            for word2 in obj2[\"PRON\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"PRON\"] += 1\n",
    "    #VERB\n",
    "    if(len(obj1[\"VERB\"])>0):\n",
    "        result[\"VERB\"] = 0\n",
    "        for word1 in obj1[\"VERB\"]:\n",
    "            for word2 in obj2[\"VERB\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"VERB\"] += 1 \n",
    "    #ADJ \n",
    "    if(len(obj1[\"ADJ\"])>0):\n",
    "        result[\"ADJ\"] = 0\n",
    "        status = 0\n",
    "        for i in range(len(obj1[\"ADJ\"])): \n",
    "            word1 = obj1[\"ADJ\"][i]\n",
    "            for j in range(len(obj2[\"ADJ\"])): \n",
    "                word2 = obj2[\"ADJ\"][j]\n",
    "                tempArr = []\n",
    "                for syn in wordnet.synsets(word2):\n",
    "                    for l in syn.lemmas():\n",
    "                        tempArr.append(l.name())\n",
    "                for tempWord in tempArr:\n",
    "                    if(word1 == tempWord):\n",
    "                        status = 1\n",
    "                        sentence2 = sentence2.replace(word2,word1)\n",
    "                        result[\"ADJ\"] += 1\n",
    "                        break\n",
    "\n",
    "    #ADV\n",
    "    if(len(obj1[\"ADV\"])>0):\n",
    "        result[\"ADV\"] = 0\n",
    "        for word1 in obj1[\"ADV\"]:\n",
    "            for word2 in obj2[\"ADV\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"ADV\"] += 1 \n",
    "    #NUM     \n",
    "    if(len(obj1[\"NUM\"])>0):\n",
    "        #NUM2WORD\n",
    "        for i in range(len(obj1[\"NUM\"])):\n",
    "            if(obj1[\"NUM\"][i].isdigit()):\n",
    "                obj1[\"NUM\"][i] = num2words(obj1[\"NUM\"][i])\n",
    "        for i in range(len(obj2[\"NUM\"])):\n",
    "            if(obj2[\"NUM\"][i].isdigit()):\n",
    "                obj2[\"NUM\"][i] = num2words(obj2[\"NUM\"][i])\n",
    "        #NORMAL\n",
    "        result[\"NUM\"] = 0\n",
    "        for word1 in obj1[\"NUM\"]:\n",
    "            for word2 in obj2[\"NUM\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"NUM\"] += 1\n",
    "    #SYM\n",
    "    if(len(obj1[\"SYM\"])>0):\n",
    "        result[\"SYM\"] = 0\n",
    "        for word1 in obj1[\"SYM\"]:\n",
    "            for word2 in obj2[\"SYM\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"SYM\"] += 1\n",
    "    #X-OTHERS\n",
    "    if(len(obj1[\"X\"])>0):\n",
    "        result[\"X\"] = 0\n",
    "        for word1 in obj1[\"X\"]:\n",
    "            for word2 in obj2[\"X\"]:\n",
    "                if(word1 == word2):\n",
    "                    result[\"X\"] += 1\n",
    "    tempObj = {\n",
    "        'NOUN':len(obj1['NOUN']),\n",
    "        'PROPN':len(obj1['PROPN']),\n",
    "        'PRON':len(obj1['PRON']),\n",
    "        'VERB':len(obj1['VERB']),\n",
    "        'ADJ':len(obj1['ADJ']),\n",
    "        'ADV':len(obj1['ADV']),\n",
    "        'SYM':len(obj1['SYM']),\n",
    "        'NUM':len(obj1['NUM']),\n",
    "        'X':len(obj1['X'])\n",
    "    }\n",
    "    res = {\n",
    "        'teachMark':tempObj,\n",
    "        'studMark':result\n",
    "    }\n",
    "    #TUPLE UNPACK AND GET BOTH VALUES\n",
    "    return res,sentence2\n",
    "\n",
    "#Is active\n",
    "def is_active(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    passive_rule = [{'DEP': 'nsubjpass'}, {'DEP': 'aux', 'OP': '*'}, {'DEP': 'auxpass'}, {'TAG': 'VBN'}]\n",
    "    matcher.add('Passive', None, passive_rule)\n",
    "    matches = matcher(doc)\n",
    "    if matches:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#These sentences will be with replaced words for sent2 alone\n",
    "#For NOUN check\n",
    "def NCsplitOnVerb(sentence):\n",
    "    sent = {}\n",
    "    doc = nlp(sentence)\n",
    "    sent[\"TYPE\"] = is_active(sentence)\n",
    "    sent[\"NPV\"] = [token.lemma_.lower() for token in doc if token.pos_==\"NOUN\" \n",
    "     or token.pos_==\"PRON\" \n",
    "     or token.pos_==\"PROPN\"\n",
    "     or token.pos_==\"VERB\" and token.lemma_.lower()!=\"be\"]\n",
    "    sent[\"NPV\"] = ' '.join(sent[\"NPV\"])\n",
    "    sent[\"V\"] = [token.lemma_.lower() for token in doc if token.pos_==\"VERB\" and token.lemma_.lower()!=\"be\"]\n",
    "    sent[\"NP\"]= sent[\"NPV\"].split(sent[\"V\"][0])\n",
    "    sent[\"NP\"] = [word.replace(' ','') for word in sent[\"NP\"]]\n",
    "    sent[\"NP\"] = [''.join(sorted(word)) for word in sent[\"NP\"]]\n",
    "    return sent\n",
    "\n",
    "#______________MAIN______________\n",
    "#Check order of appearance of a noun\n",
    "def checkOrderOfNoun(sent1,sent2):\n",
    "    sent1obj = NCsplitOnVerb(sent1)\n",
    "    sent2obj = NCsplitOnVerb(sent2)\n",
    "    index1 = []\n",
    "    index2 = []\n",
    "    for i in range(len(sent1obj[\"NP\"])):\n",
    "        index1.append(i)\n",
    "        try:\n",
    "            index2.append(sent2obj[\"NP\"].index(sent1obj[\"NP\"][i]))\n",
    "        except:\n",
    "            return False\n",
    "    if(sent1obj[\"TYPE\"]==sent2obj[\"TYPE\"]):\n",
    "        #len(index1) = len(index2)\n",
    "        for i in range(len(index1)):\n",
    "            if(index1[i]!=index2[i]):\n",
    "                return False\n",
    "        return True\n",
    "    elif(sent1obj[\"TYPE\"]!=sent2obj[\"TYPE\"]):\n",
    "        for i in range(len(index1)):\n",
    "            if(index1[i]==index2[i]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "#For ADJ check\n",
    "def ACsplitOnVerb(sentence):\n",
    "    sent = {}\n",
    "    doc = nlp(sentence)\n",
    "    sent[\"TYPE\"] = is_active(sentence)\n",
    "    sent[\"NPVA\"] = [token.lemma_.lower() for token in doc if token.pos_==\"NOUN\" \n",
    "     or token.pos_==\"PRON\" \n",
    "     or token.pos_==\"PROPN\"\n",
    "     or token.pos_==\"ADJ\"\n",
    "     or token.pos_==\"VERB\" and token.lemma_.lower()!=\"be\"]\n",
    "    sent[\"NPVA\"] = ' '.join(sent[\"NPVA\"])\n",
    "    sent[\"V\"] = [token.lemma_.lower() for token in doc if token.pos_==\"VERB\" and token.lemma_.lower()!=\"be\"]\n",
    "    sent[\"NPA\"]= sent[\"NPVA\"].split(sent[\"V\"][0])\n",
    "    sent[\"NPA\"] = [word.replace(' ','') for word in sent[\"NPA\"]]\n",
    "    sent[\"NPA\"] = [''.join(sorted(word)) for word in sent[\"NPA\"]]\n",
    "    return sent\n",
    "\n",
    "#______________MAIN______________     \n",
    "#Check order of appearance of an adjective\n",
    "def checkOrderOfAdjective(sent1,sent2):\n",
    "    sent1obj = ACsplitOnVerb(sent1)\n",
    "    sent2obj = ACsplitOnVerb(sent2)\n",
    "    index1 = []\n",
    "    index2 = []\n",
    "    for i in range(len(sent1obj[\"NPA\"])):\n",
    "        index1.append(i)\n",
    "        try:\n",
    "            index2.append(sent2obj[\"NPA\"].index(sent1obj[\"NPA\"][i]))\n",
    "        except:\n",
    "            return False\n",
    "    if(sent1obj[\"TYPE\"]==sent2obj[\"TYPE\"]):\n",
    "        #len(index1) = len(index2)\n",
    "        for i in range(len(index1)):\n",
    "            if(index1[i]!=index2[i]):\n",
    "                return False\n",
    "        return True\n",
    "    elif(sent1obj[\"TYPE\"]!=sent2obj[\"TYPE\"]):\n",
    "        for i in range(len(index1)):\n",
    "            if(index1[i]==index2[i]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "#teach and student are array of sentences\n",
    "#AFTER CHUNKING\n",
    "######## ADJUST SIM SCORE MULTIPLICATION\n",
    "def compareMain(teach,student):\n",
    "    arr=[]\n",
    "    for i in range(len(teach)):\n",
    "        obj={}\n",
    "        obj['s']=teach[i]\n",
    "        obj['c']=0\n",
    "        arr.append(obj)\n",
    "    teach = arr\n",
    "    print(teach)\n",
    "    for teachObj in teach:\n",
    "        for sent in student:\n",
    "            res , sent2 = compare(teachObj['s'],sent)\n",
    "            simScore = simCheck(res)\n",
    "            if(res['teachMark']['VERB']>0):\n",
    "                if(checkOrderOfNoun(teachObj['s'],sent2)==False):\n",
    "                    simScore*=0\n",
    "                if(checkOrderOfAdjective(teachObj['s'],sent2)==False):\n",
    "                    simScore*=0.95              #################\n",
    "                if(simScore>0.4):           #################\n",
    "                    teachObj['SIM'] = simScore\n",
    "                    teachObj['c']=1\n",
    "    #teach is an object with attribute 's' , 'c' and 'SIM' if matched(result)\n",
    "    return teach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_active(\"Jack is eating a chicken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_active(\"a chicken is being eaten by Jack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'s': 'Jack is eating a chicken', 'c': 0}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'s': 'Jack is eating a chicken', 'c': 1, 'SIM': 1.0}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compareMain([\"Jack is eating a chicken\"] , [\"a chicken is being eaten by Jack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'teachMark': {'NOUN': 1,\n",
       "   'PROPN': 1,\n",
       "   'PRON': 0,\n",
       "   'VERB': 1,\n",
       "   'ADJ': 0,\n",
       "   'ADV': 0,\n",
       "   'SYM': 0,\n",
       "   'NUM': 0,\n",
       "   'X': 0},\n",
       "  'studMark': {'NOUN': 1, 'PROPN': 1, 'VERB': 1}},\n",
       " 'a chicken is being eaten by Jack')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(\"Jack is eating a chicken\",\"a chicken is being eaten by Jack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
